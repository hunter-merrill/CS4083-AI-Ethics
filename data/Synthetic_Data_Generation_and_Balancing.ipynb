{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the file ID for the uploaded CSV\n",
        "FILE_ID = \"alzheimers_disease_data.csv\"\n",
        "OUTPUT_FILENAME = \"balanced_alzheimers_data.csv\"\n",
        "\n",
        "# --- 1. Load the Data ---\n",
        "try:\n",
        "    df = pd.read_csv(FILE_ID)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file with ID {FILE_ID} was not found.\")\n",
        "    # Create a dummy DataFrame for demonstration if the file doesn't load\n",
        "    # This block should be removed in a live environment where file access is guaranteed\n",
        "    data = {\n",
        "        'PatientID': [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
        "        'Age': [70, 65, 80, 72, 68, 75, 60, 85, 71, 69],\n",
        "        'Ethnicity': [0, 1, 0, 2, 0, 1, 0, 0, 2, 0], # 0: 6, 1: 2, 2: 2 (Majority is 0)\n",
        "        'BMI': [25.1, 22.5, 30.0, 26.5, 24.9, 23.3, 21.0, 29.5, 27.0, 24.5],\n",
        "        'Diagnosis': [1, 0, 1, 1, 0, 0, 1, 1, 0, 1]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Identify numerical columns for noise injection (based on typical Alzheimer's dataset features)\n",
        "# 'PatientID' and categorical columns will be excluded from noise.\n",
        "numerical_cols = [\n",
        "    'Age', 'BMI', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n",
        "    'SleepQuality', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal',\n",
        "    'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides',\n",
        "    'MMSE', 'FunctionalAssessment', 'ADL'\n",
        "]\n",
        "# Filter to only include columns present in the dataframe\n",
        "numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
        "\n",
        "# --- 2. Analyze Balance and Determine Needs ---\n",
        "ethnicity_counts = df['Ethnicity'].value_counts()\n",
        "if ethnicity_counts.empty:\n",
        "    print(\"Error: 'Ethnicity' column is empty or missing. Cannot balance.\")\n",
        "    exit()\n",
        "\n",
        "majority_count = ethnicity_counts.max()\n",
        "ethnicity_needs = majority_count - ethnicity_counts\n",
        "minority_ethnicities = ethnicity_needs[ethnicity_needs > 0].index.tolist()\n",
        "\n",
        "if not minority_ethnicities:\n",
        "    print(\"Dataset is already balanced. No synthetic data generated.\")\n",
        "    df.to_csv(OUTPUT_FILENAME, index=False)\n",
        "    exit()\n",
        "\n",
        "print(f\"Original Ethnicity Counts:\\n{ethnicity_counts}\")\n",
        "print(f\"Majority Class Count: {majority_count}\")\n",
        "\n",
        "# --- 3. Generate Synthetic Data ---\n",
        "synthetic_data_list = []\n",
        "current_max_id = df['PatientID'].max() if 'PatientID' in df.columns else 0\n",
        "new_id_counter = current_max_id + 1\n",
        "\n",
        "for eth_id in minority_ethnicities:\n",
        "    needed_samples = ethnicity_needs[eth_id]\n",
        "    print(f\"Generating {needed_samples} samples for Ethnicity {eth_id}\")\n",
        "\n",
        "    # Subset the original data for this ethnicity\n",
        "    minority_df = df[df['Ethnicity'] == eth_id].copy()\n",
        "\n",
        "    if minority_df.empty:\n",
        "        print(f\"Warning: No data found for Ethnicity {eth_id}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Sample original data with replacement to create the synthetic base\n",
        "    sample_indices = np.random.choice(minority_df.index, size=needed_samples, replace=True)\n",
        "    synthetic_base_df = minority_df.loc[sample_indices].copy()\n",
        "    synthetic_base_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # 3a. Add noise to numerical columns\n",
        "    for col in numerical_cols:\n",
        "        if col in synthetic_base_df.columns:\n",
        "            # Calculate a small noise factor based on 5% of the standard deviation\n",
        "            std_dev = minority_df[col].std()\n",
        "            noise_scale = std_dev * 0.05\n",
        "\n",
        "            # Ensure a minimum noise scale for features with zero variance\n",
        "            if noise_scale < 1e-6:\n",
        "                noise_scale = 0.01 # Small fixed noise if STD is near zero\n",
        "\n",
        "            # Generate and add Gaussian noise\n",
        "            noise = np.random.normal(0, noise_scale, size=needed_samples)\n",
        "            synthetic_base_df[col] += noise\n",
        "\n",
        "            # Post-processing: ensure Age is an integer and values are non-negative\n",
        "            if col == 'Age':\n",
        "                synthetic_base_df[col] = synthetic_base_df[col].round().astype(int)\n",
        "\n",
        "            synthetic_base_df[col] = synthetic_base_df[col].apply(lambda x: max(0, x))\n",
        "\n",
        "    # 3b. Assign unique PatientIDs\n",
        "    if 'PatientID' in synthetic_base_df.columns:\n",
        "        new_ids = np.arange(new_id_counter, new_id_counter + needed_samples)\n",
        "        synthetic_base_df['PatientID'] = new_ids\n",
        "        new_id_counter += needed_samples\n",
        "\n",
        "    synthetic_data_list.append(synthetic_base_df)\n",
        "\n",
        "# --- 4. Combine and Save Data ---\n",
        "if synthetic_data_list:\n",
        "    synthetic_df = pd.concat(synthetic_data_list, ignore_index=True)\n",
        "    balanced_df = pd.concat([df, synthetic_df], ignore_index=True)\n",
        "else:\n",
        "    balanced_df = df\n",
        "\n",
        "# Final check of counts\n",
        "print(\"\\nFinal Ethnicity Counts:\")\n",
        "print(balanced_df['Ethnicity'].value_counts())\n",
        "\n",
        "# Save the resulting DataFrame to the specified CSV file\n",
        "balanced_df.to_csv(OUTPUT_FILENAME, index=False)\n",
        "\n",
        "print(f\"\\nSuccessfully generated and saved balanced data to {OUTPUT_FILENAME}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Ethnicity Counts:\n",
            "Ethnicity\n",
            "0    1278\n",
            "1     454\n",
            "3     211\n",
            "2     206\n",
            "Name: count, dtype: int64\n",
            "Majority Class Count: 1278\n",
            "Generating 824 samples for Ethnicity 1\n",
            "Generating 1067 samples for Ethnicity 3\n",
            "Generating 1072 samples for Ethnicity 2\n",
            "\n",
            "Final Ethnicity Counts:\n",
            "Ethnicity\n",
            "0    1278\n",
            "3    1278\n",
            "1    1278\n",
            "2    1278\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Successfully generated and saved balanced data to balanced_alzheimers_data.csv\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut1DSUvjM_xM",
        "outputId": "95ff83d4-40af-44fe-df0c-ade3c469f5ed"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}